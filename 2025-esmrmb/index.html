<!DOCTYPE html>
<html>
  <head>
    <title>Preprocessing & pipelines | 2.10.2025</title>
    <meta charset="utf-8">
    <meta name="grammarly" content="false">
    <meta name="google" content="notranslate">
    <link rel="stylesheet" type="text/css" href="../remark/asciinema-player/asciinema-player.css?v=5" />
    <link rel="stylesheet" type="text/css" href="../remark/nipreps.css?v=5" />
    <link rel="stylesheet" href="../remark/roulette.css?v=5" />
  </head>
  <body>
<script src="../remark/asciinema-player/asciinema-player.min.js?v=5"></script>
<script src="https://kit.fontawesome.com/015d4b01de.js" crossorigin="anonymous"></script>
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true},
      jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
      extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
      TeX: {
      extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
      equationNumbers: {
      autoNumber: "AMS"
      }
    }
  });
</script>


<textarea id="source">
name: title
layout: true
class: cover
---
count: false
counter: false


.section-mark.center[
<a href="https://www.nipreps.org/presentations/2025-esmrmb/index.html">
  <object type="image/svg+xml" data="images/qr-talk-url.svg" style="width: 20%"></object>
  <br />
  https://www.nipreps.org/presentations/2025-esmrmb/index.html
</a>

<br />
<br />

## Preprocessing & pipelines

Oscar Esteban &lt;<code>nipreps@gmail.com</code>>

<br />

### ESMRMB Microstructure workshop — Marseille, Oct 8, 2025
]

???

---
name: newsection
layout: true

.perma-sidebar[
<p class="rotate">
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0; height: 20px; padding-top: 6px;" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a>
  <span style="padding-left: 10px; font-weight: 600;">Preprocessing & pipelines (2.10.2025)</span>
</p>
]

---

# About me

.large[
**Data scientist** who plays with brain data & **open science** advocate.
]

.right-column3.center[
<a href="https://www.nipreps.org/presentations/2025-esmrmb/index.html">
  <object type="image/svg+xml" data="images/qr-talk-url.svg" style="width: 80%"></object>
  <br />
  Link to slides
</a>
]

.pad-top.left-column3[
.people-table.larger[

| | |
|---:|---|
| ![oscar-esteban](https://www.axonlab.org/images/teampic/OscarEsteban-300x300.jpg) | **Oscar Esteban** <br /> Associate Professor & Head of [AxonLab](https://www.axonlab.org) <br /> School of Engineering <br /> HES-SO University of Applied Sciences and Arts Western Switzerland |
]


* Research & Teaching FNS Fellow (2025) @ Lausanne University Hospital
* PD (2020) @ Stanford University
* Ph.D. (2015) @ Universidad Politécnica de Madrid <br />ESKAS (2012) @ EPFL


]

---

# NiPreps: NeuroImaging PREProcessing toolS

.boxed-content[
<br />
.larger.center[
"*analysis-grade*" data <i class="fa-solid fa-circle-right"></i> data **directly consumable by analyses**
]

.pull-left[
<br />
<br />
*Analysis-grade* data is an analogy to the concept of "*sushi-grade (or [sashimi-grade](https://en.wikipedia.org/wiki/Sashimi)) fish*" in that both are:

.large[<i class="fa-solid fa-circle-right"></i> **minimally preprocessed**,]

and

.large[<i class="fa-solid fa-circle-right"></i> **safe to consume** directly.]
]

.pull-right.center[
<img src="https://raw.githubusercontent.com/nipreps/identity/refs/heads/main/nipreps-general/nipreps-transparent.png" width="100%" />
<a href="https://www.nipreps.org"><object type="text/xml+svg" data="https://www.nipreps.org/identity/nipreps-general/qr-code.svg" style="width: 40%"></object><br />
www.nipreps.org</a>
]
]

???

In computational neuroscience I'm recognized by my standardization efforts.

NiPreps is a framework for standardized preprocessing pipelines in neuroimaging.

I often use the “sushi-grade” analogy

just like sushi-grade fish is minimally processed but safe to consume,

NiPreps yields “analysis-grade” data, with minimal processing interventions but ready for direct machine learning ingestion.

---

# NiPreps: 113 members + a robot
.boxed-content.center[
<img style="width: 90%" src="https://raw.githubusercontent.com/nipreps/identity/refs/heads/main/nipreps-general/nipreps-members.png" />
]

---
counter: false

.section-mark.center[
# About *us*

.large.gray-text[AI-generated, fictional characters]
]


???

We can’t all introduce ourselves, so I brought six fictional colleagues who might feel familiar. If you see yourself in one of these—or a blend—you’re in the right room.

---
count: false

# Thảo Nguyễn (she/her)

.boxed-content[
.pull-right.center[
<img alt="Smiling Vietnamese graduate student in a simple sweater on a warm-gray background." src="images/characters-nguyen.png" style="width: 70%" />
]
.pull-left.large[
* **Role & place.** 2nd-year PhD student (computational neuroscience), Lyon. Multilingual; learning French.

* **Tools.** Python, Jupyter, some Git/GitHub; limited HPC access.

* **Goals.** Learn practical preprocessing, get a merged PR, build contacts.

]
]

???

Thảo Nguyễn is a 2nd year Ph.D. student in Lyon. She's very committed and loves her program, although cultural clashes have made the ride a bit bumpy at times (e.g., she's still learning French). She's coming to this workshop because it's close to Lyon and her mentor thought it would be a good opportunity to learn new things and make valuable connections in a budget.

---

# Dr. Amine Bensalem (he/him)

.boxed-content[
.pull-right.center[
<img alt="Neuroradiologist in a white coat, warm‑gray background." src="images/characters-bensalem.png" style="width: 70%" />
]
.pull-left.large[
* **Role & place.** Neuroradiologist, university hospital in Marseille.

* **Tools.** Vendor consoles, PACS, some MATLAB; minimal command line.

* **Goals.** Trustworthy QC reports; fast, interpretable steps he can explain to colleagues.
]
]

???

---

# Sofia Rossi (she/her)

.boxed-content[
.pull-right.center[
<img alt="Software engineer in a blazer with glasses on warm‑gray background." src="images/characters-rossi.png" style="width: 70%" />
]
.pull-left.large[
* **Role & place.** RSE at an imaging core, Milan.

* **Tools.** Python, containers (Docker/Singularity), CI, BIDS, SLURM.

* **Goals.** Reproducible pipelines; clear governance & licensing; faster re‑runs.
]
]

???

---

# Kofi Mensah (he/him)

.boxed-content[
.pull-right.center[
<img alt="MRI physicist in a dark shirt, light‑gray background." src="images/characters-mensah.png" style="width: 70%" />
]
.pull-left.large[
* **Role & place.** MRI physicist postdoc, visiting scholar (Paris↔Accra).

* **Tools.** Sequence design, vendor gradients, MATLAB/Python, CUDA familiarity.

* **Goals.** See where acquisition choices meet preprocessing (PE polarity, eddy, Gibbs).
]
]

???

---

# Priya Shah (she/her)

.boxed-content[
.pull-right.center[
<img alt="Data scientist with hair tied back on light-gray background." src="images/characters-shah.png" style="width: 70%" />
]
.pull-left.large[
* **Role & place.** Data scientist (connectomics), leads a team of 10 RSEs, postdocs and undergrads. London.

* **Tools.** Python, NumPy/Pandas, Nipype, stats; some R; comfortable with GitHub.

* **Goals.** Quantitative QC; stable interfaces for downstream stats; containers.
]
]

???

---

# Lucas Müller (he/him)

.boxed-content[
.pull-right.center[
<img alt="R&D engineer in a navy sweater on warm‑gray background." src="images/characters-muller.png" style="width: 70%" />
]
.pull-left.large[
* **Role & place.** Industry R&D engineer (med‑tech imaging), Berlin.

* **Tools.** Python/C++, containers, Kubernetes; thinks in ELT/MLOps patterns.

* **Goals.** Low expectations: he's coming because his manager made him, perhaps he'll learn something.
]
]

???


---

# Objectives
<br />

.boxed-content.larger.no-bullet[
* .large[<i class="fa-solid fa-circle-right"></i> Connect **preprocessing** to **data flows**]


* .large[<i class="fa-solid fa-circle-right"></i> Adopt a **BIDS-first foundation** for I/O]

* .large[<i class="fa-solid fa-circle-right"></i> Survey what’s **available** and spot the **gaps**]

* .large[<i class="fa-solid fa-circle-right"></i> Build a minimal **dMRI preprocessing workflow** together]

* .large[<i class="fa-solid fa-circle-right"></i> Establish a **collaborative framework** & tooling]

* .large[<i class="fa-solid fa-circle-right"></i> Strengthen **reproducibility** and **scaling**]
]

</textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
    <script>
      // Use: ![:img Alt text with spaces but not commas, 50%](image.png)
      remark.macros.img = function (altText, width) {
        var url = this;
        return '<img alt="' + altText + '" src="' + url + '" style="width: ' + width + '" />';
      };
      // Use: ![:video](10.5129/10234)
      remark.macros.video = function (width) {
        var url = this;
        return '<video src="' + url + '" width="' + width + '" preload="auto" controls />';
      };
      // Use: ![:doi](10.5129/10234)
      remark.macros.doi = function () {
        var doi = this;
        return '<a href="https://doi.org/' + doi + '">' + doi + '</a>';
      };

      var slideshow = remark.create({
          highlightStyle: 'monokai',
          highlightLanguage: 'remark',
          highlightLines: true,
          countIncrementalSlides: false,
          highlightSpans: true,
          ratio: '16:9'
      });

      // Now retrieve all IDs of asciinema casts
      const allcasts = new Map();

      slideshow.on('afterShowSlide', function (slide) {
        // Slide is the slide being navigated
        var slideNumber = slide.getSlideIndex();
        var element = document.getElementsByClassName("remark-visible")[0].getElementsByClassName('asciicast')
        if (element.length == 0 ) {
          return;
        }

        if (allcasts.has(slideNumber)) {
          allcasts.get(slideNumber).play();
          return;
        }

        var castid = element[0].attributes["id"].value;
        allcasts.set(slideNumber, AsciinemaPlayer.create(
            `images/${castid}.cast`,
            document.getElementById(castid),
            { autoPlay: true, speed: 1, idle_time_limit: 8, rows: 24, cols: 100 }
        ));

      });
      slideshow.on('beforeHideSlide', function (slide) {
        // Slide is the slide being navigated
        var slideNumber = slide.getSlideIndex();
        if (allcasts.has(slideNumber)) {
          allcasts.get(slideNumber).pause();
        }
      });
    </script>
    <script>
    (function attachTimers(slideshow) {
      const SEL = 'span.timer';

      // --- tiny parser: "1h 5m 30s", "10 min", "mm:ss", "hh:mm:ss", or bare minutes ---
      function parseSecs(s) {
        s = (s || '').trim().toLowerCase();
        let m;
        if ((m = s.match(/^(\d{1,2}):([0-5]?\d):([0-5]?\d)$/))) return (+m[1])*3600 + (+m[2])*60 + (+m[3]);
        if ((m = s.match(/^([0-5]?\d):([0-5]?\d)$/)))          return (+m[1])*60   + (+m[2]);
        let total = 0, hit = false;
        s.replace(/(\d+(?:\.\d+)?)\s*(h|hr|hrs|hour|hours|m|min|mins|minute|minutes|s|sec|secs|second|seconds)\b/g,
          (_, n, u) => { hit = true; n = parseFloat(n);
            if (/^h/.test(u)) total += Math.round(n*3600);
            else if (/^m(?!s)/.test(u)) total += Math.round(n*60);
            else total += Math.round(n);
          });
        if (hit) return total;
        const bare = parseFloat(s);
        return Number.isFinite(bare) ? Math.round(bare*60) : null; // bare number = minutes
      }
      function fmt(secs) {
        secs = Math.max(0, Math.floor(secs));
        const h = Math.floor(secs/3600), m = Math.floor((secs%3600)/60), s = secs%60;
        return h ? `${h} hr ${m} min` : (m ? `${m} min ${s} sec` : `${s} sec`);
      }

      function start(el, secs) {
        if (el.dataset.timerRunning === '1') return;
        if (!el.dataset.original) el.dataset.original = el.textContent;
        el.dataset.timerRunning = '1';
        el.classList.add('started');
        const end = Date.now() + secs*1000;
        const tick = () => {
          const remain = Math.max(0, Math.floor((end - Date.now())/1000));
          el.textContent = fmt(remain);
          if (remain <= 0) { stop(el); el.classList.add('finished'); if (el.dataset.done) el.textContent = el.dataset.done; }
        };
        el.dataset.timerId = String(setInterval(tick, 500));
        tick();
      }
      function stop(el) { if (el.dataset.timerId) clearInterval(+el.dataset.timerId); delete el.dataset.timerId; delete el.dataset.timerRunning; }
      function reset(el) { stop(el); el.classList.remove('started','finished'); if (el.dataset.original) el.textContent = el.dataset.original; }

      function initIn(root) {
        root.querySelectorAll(SEL).forEach(el => {
          let secs = el.dataset.seconds ? parseInt(el.dataset.seconds,10) : null;
          if (!Number.isFinite(secs) && el.dataset.until) {
            const until = new Date(el.dataset.until); if (!isNaN(+until)) secs = Math.max(0, Math.round((until - Date.now())/1000));
          }
          if (!Number.isFinite(secs)) secs = parseSecs(el.textContent);
          if (Number.isFinite(secs)) start(el, secs);
        });
      }
      function resetIn(root) { root.querySelectorAll(SEL).forEach(reset); }

      const visibleSlideRoots = () =>
        Array.from(document.querySelectorAll('.remark-slide-container.remark-visible .remark-slide-content'));

      slideshow.on('afterShowSlide', () => visibleSlideRoots().forEach(initIn));
      slideshow.on('beforeHideSlide', () => visibleSlideRoots().forEach(resetIn));

      // kick the initially rendered slide
      visibleSlideRoots().forEach(initIn);
    })(slideshow);
    </script>
    <!-- Add the roulette module -->
    <script src="../remark/roulette.js?v=4"></script>
    <script>
      // Initialize once
      Roulette.init(slideshow);
    </script>
  </body>
</html>
